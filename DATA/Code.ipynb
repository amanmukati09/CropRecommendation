{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b69845db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 60.34%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Read the data from CSV file\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest model\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = 1 - mse / y_test.var()\n",
    "\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f817d339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7233/7233 - 43s - loss: 4.0482e-04 - 43s/epoch - 6ms/step\n",
      "Epoch 2/100\n",
      "7233/7233 - 40s - loss: 3.2261e-04 - 40s/epoch - 5ms/step\n",
      "Epoch 3/100\n",
      "7233/7233 - 47s - loss: 3.0911e-04 - 47s/epoch - 6ms/step\n",
      "Epoch 4/100\n",
      "7233/7233 - 39s - loss: 2.9954e-04 - 39s/epoch - 5ms/step\n",
      "Epoch 5/100\n",
      "7233/7233 - 40s - loss: 2.9294e-04 - 40s/epoch - 6ms/step\n",
      "Epoch 6/100\n",
      "7233/7233 - 40s - loss: 2.8888e-04 - 40s/epoch - 6ms/step\n",
      "Epoch 7/100\n",
      "7233/7233 - 39s - loss: 2.8590e-04 - 39s/epoch - 5ms/step\n",
      "Epoch 8/100\n",
      "7233/7233 - 41s - loss: 2.8227e-04 - 41s/epoch - 6ms/step\n",
      "Epoch 9/100\n",
      "7233/7233 - 40s - loss: 2.8048e-04 - 40s/epoch - 6ms/step\n",
      "Epoch 10/100\n",
      "7233/7233 - 41s - loss: 2.7847e-04 - 41s/epoch - 6ms/step\n",
      "Epoch 11/100\n",
      "7233/7233 - 38s - loss: 2.7422e-04 - 38s/epoch - 5ms/step\n",
      "Epoch 12/100\n",
      "7233/7233 - 38s - loss: 2.7352e-04 - 38s/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "7233/7233 - 40s - loss: 2.7164e-04 - 40s/epoch - 6ms/step\n",
      "Epoch 14/100\n",
      "7233/7233 - 39s - loss: 2.7066e-04 - 39s/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "7233/7233 - 39s - loss: 2.6841e-04 - 39s/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "7233/7233 - 39s - loss: 2.6492e-04 - 39s/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "7233/7233 - 38s - loss: 2.6380e-04 - 38s/epoch - 5ms/step\n",
      "Epoch 18/100\n",
      "7233/7233 - 38s - loss: 2.6445e-04 - 38s/epoch - 5ms/step\n",
      "Epoch 19/100\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# Read the data from CSV file\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "\n",
    "# Prepare the data\n",
    "data = df[['DewPointC', 'WindGustKmph', 'cloudcover', 'humidity', 'pressure', 'tempC', 'winddirDegree', 'windspeedKmph', 'precipMM']].values\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data = scaler.fit_transform(data)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_size = int(len(data) * 0.8)\n",
    "test_size = len(data) - train_size\n",
    "train_data, test_data = data[0:train_size,:], data[train_size:len(data),:]\n",
    "\n",
    "# Create the input and output datasets\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        X.append(dataset[i:(i+look_back), :-1])\n",
    "        Y.append(dataset[i + look_back, -1])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "look_back = 5\n",
    "train_X, train_Y = create_dataset(train_data, look_back)\n",
    "test_X, test_Y = create_dataset(test_data, look_back)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(look_back, 8)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_X, train_Y, epochs=100, batch_size=32, verbose=2)\n",
    "\n",
    "# Evaluate the model\n",
    "train_score = model.evaluate(train_X, train_Y, verbose=0)\n",
    "test_score = model.evaluate(test_X, test_Y, verbose=0)\n",
    "print('Train Score: %.2f MSE (%.2f RMSE)' % (train_score, np.sqrt(train_score)))\n",
    "print('Test Score: %.2f MSE (%.2f RMSE)' % (test_score, np.sqrt(test_score)))\n",
    "\n",
    "# Make predictions\n",
    "train_predict = model.predict(train_X)\n",
    "test_predict = model.predict(test_X)\n",
    "train_predict = scaler.inverse_transform(np.concatenate((train_X[:,:,1:], train_predict), axis=2))[:, -1, -1]\n",
    "train_Y = scaler.inverse_transform(np.concatenate((train_X[:,:,1:], train_Y.reshape(-1, 1)), axis=2))[:, -1, -1]\n",
    "test_predict = scaler.inverse_transform(np.concatenate((test_X[:,:,1:], test_predict), axis=2))[:, -1, -1]\n",
    "test_Y = scaler.inverse_transform(np.concatenate((test_X[:,:,1:], test_Y.reshape(-1, 1)), axis=2))[:, -1, -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85ba4494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.32%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Read the data from CSV file\n",
    "df = pd.read_csv(\"ocd.csv\")\n",
    "\n",
    "# Split the data into features and labels\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
